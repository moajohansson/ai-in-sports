{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import math\n",
    "import keras\n",
    "from random import shuffle\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Flatten, Input, TimeDistributed\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.normpath('/Users/mariekorneliusson/documents/AiSports/Strike_Data_As_Np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_First = np.load(path + '/' + 'X_First_Skier.npy')\n",
    "Y_First = np.load(path + '/' + 'Y_First_Skier.npy')\n",
    "feature_list_First = []\n",
    "with open(path + \"/keys_First_Skier.txt\", \"r\") as f:\n",
    "      for line in f:\n",
    "        feature_list_First.append(line.strip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Second = np.load(path + '/' + 'X_Second_Skier.npy')\n",
    "Y_Second = np.load(path + '/' + 'Y_Second_Skier.npy')\n",
    "feature_list_Second = []\n",
    "with open(path + \"/keys_Second_Skier.txt\", \"r\") as f:\n",
    "      for line in f:\n",
    "        feature_list_Second.append(line.strip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Third = np.load(path + '/' + 'X_Third_Skier.npy')\n",
    "Y_Third = np.load(path + '/' + 'Y_Third_Skier.npy')\n",
    "feature_list_Third = []\n",
    "with open(path + \"/keys_Third_Skier.txt\", \"r\") as f:\n",
    "      for line in f:\n",
    "        feature_list_Third.append(line.strip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "feature_Dict = {i:feature_list_Second[i] for i in range(len(feature_list_Second)-1)}\n",
    "print(len(feature_Dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(452, 140, 22)\n",
      "(382, 140, 18)\n",
      "(844, 140, 22)\n",
      "(452, 4)\n",
      "(382, 4)\n",
      "(844, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_First.shape)\n",
    "print(X_Second.shape)\n",
    "print(X_Third.shape)\n",
    "print(Y_First.shape)\n",
    "print(Y_Second.shape)\n",
    "print(Y_Third.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_test_train_data(X_List,Y_List,ratio,time_step,dimX,nbr_of_classes):\n",
    "    # Function to split such that train data contains same number of training data for each skier.\n",
    "    # Returns train X and Y \n",
    "    # Returns list of test X and Y, contains a merged test set for all skiers, and test sets for each skier as seperate sets.  \n",
    "    \n",
    "    nbr_of_data = len(X_List)\n",
    "    min_samples = min([x.shape[0] for x in X_List])\n",
    "    h = int((1-ratio)*min_samples)\n",
    "    nbr_of_test = [x.shape[0]-h for x in X_List]\n",
    "    X = np.zeros((h*nbr_of_data,time_step,dimX))\n",
    "    Y = np.zeros((h*nbr_of_data,nbr_of_classes))\n",
    "    X_Test_List = [np.zeros((sum(nbr_of_test),time_step,dimX))]\n",
    "    Y_Test_List = [np.zeros((sum(nbr_of_test),nbr_of_classes))]\n",
    "    \n",
    "    for i in range(nbr_of_data):\n",
    "        x_d = np.zeros((nbr_of_test[i],time_step,dimX))\n",
    "        y_d = np.zeros((nbr_of_test[i],nbr_of_classes))\n",
    "        X_Test_List.append(x_d)\n",
    "        Y_Test_List.append(y_d)\n",
    "\n",
    "    test_samp_prev = 0 \n",
    "    for i in range(nbr_of_data):\n",
    "        x = X_List[i][:,:,:dimX]\n",
    "        y = Y_List[i]\n",
    "        test_samp = nbr_of_test[i] + test_samp_prev\n",
    "        X[h*i:h*(i+1),:,:] = x[:h,:,:]\n",
    "        Y[h*i:h*(i+1),:] = y[:h,:]\n",
    "        X_Test_List[0][test_samp_prev:test_samp,:,:] = x[h:,:,:]\n",
    "        Y_Test_List[0][test_samp_prev:test_samp,:] = y[h:,:]\n",
    "        X_Test_List[i+1] = x[h:,:,:]\n",
    "        Y_Test_List[i+1] = y[h:,:]\n",
    "        test_samp_prev = test_samp\n",
    "        \n",
    "    return X,Y,X_Test_List,Y_Test_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_X = len(feature_Dict)\n",
    "X_List = [X_First,X_Second,X_Third]\n",
    "Y_List = [Y_First,Y_Second,Y_Third]\n",
    "ratio = 0.2\n",
    "time_step = 140\n",
    "nbr_of_classes = 4\n",
    "X,Y,X_Test_List,Y_Test_List = split_to_test_train_data(X_List,Y_List,ratio,time_step,dim_X,nbr_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_labels(Y,Y_Test_List,time_step):\n",
    "    \n",
    "    Y_Test_List_New = []\n",
    "    \n",
    "    Y_New= np.zeros((Y.shape[0],time_step,Y.shape[1]))\n",
    "    label_ind = np.where(Y == 1)\n",
    "    Y_New[label_ind[0],:,label_ind[1]] = 1\n",
    "    \n",
    "    for i in range(len(Y_Test_List)):\n",
    "        Y_old = Y_Test_List[i]\n",
    "        Y_new= np.zeros((Y_old.shape[0],time_step,Y_old.shape[1]))\n",
    "        label_ind = np.where(Y_old == 1)\n",
    "        Y_new[label_ind[0],:,label_ind[1]] = 1\n",
    "        Y_Test_List_New.append(Y_new)\n",
    "    \n",
    "    \n",
    "    return Y_New,Y_Test_List_New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(915, 140, 17)\n",
      "(915, 140, 4)\n",
      "(763, 140, 17)\n",
      "(763, 140, 4)\n"
     ]
    }
   ],
   "source": [
    "Y,Y_Test_List = reshape_labels(Y,Y_Test_List,time_step)\n",
    "X_Test = X_Test_List[0]\n",
    "Y_Test = Y_Test_List[0]\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(X_Test.shape)\n",
    "print(Y_Test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_One_Multiple_Output():\n",
    "    \n",
    "    sequence_input = Input(shape=(time_step,dim_X-1))\n",
    "    x = BatchNormalization(axis=2,input_shape=(time_step,dim_X-1), momentum=0.99, epsilon=0.001, center=True, scale=True)(sequence_input)\n",
    "    x = LSTM(64,return_sequences=True)(x)\n",
    "    preds = Dense(nbr_of_classes, activation='softmax')(x)\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(Adam(lr=0.0001),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def LSTM_One_Multiple_Output_Timedistributed():\n",
    "    \n",
    "    sequence_input = Input(shape=(time_step,dim_X-1))\n",
    "    x = BatchNormalization(axis=2,input_shape=(time_step,dim_X-1), momentum=0.99, epsilon=0.001, center=True, scale=True)(sequence_input)\n",
    "    x = LSTM(64,return_sequences=True)(x)\n",
    "    preds = TimeDistributed(Dense(nbr_of_classes, activation='softmax'))(x)\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(Adam(lr=0.0001),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 915 samples, validate on 763 samples\n",
      "Epoch 1/20\n",
      "915/915 [==============================] - 213s 233ms/step - loss: 1.2815 - acc: 0.4126 - val_loss: 1.2701 - val_acc: 0.3698\n",
      "Epoch 2/20\n",
      "915/915 [==============================] - 211s 231ms/step - loss: 0.9317 - acc: 0.6079 - val_loss: 0.9822 - val_acc: 0.5041\n",
      "Epoch 3/20\n",
      "915/915 [==============================] - 209s 228ms/step - loss: 0.7312 - acc: 0.6771 - val_loss: 0.8904 - val_acc: 0.5903\n",
      "Epoch 4/20\n",
      "915/915 [==============================] - 211s 230ms/step - loss: 0.6286 - acc: 0.7387 - val_loss: 0.8516 - val_acc: 0.6185\n",
      "Epoch 5/20\n",
      "915/915 [==============================] - 213s 233ms/step - loss: 0.5600 - acc: 0.7865 - val_loss: 0.7685 - val_acc: 0.7161\n",
      "Epoch 6/20\n",
      "915/915 [==============================] - 244s 266ms/step - loss: 0.4070 - acc: 0.8810 - val_loss: 0.8560 - val_acc: 0.7060\n",
      "Epoch 7/20\n",
      "915/915 [==============================] - 227s 248ms/step - loss: 0.3927 - acc: 0.8793 - val_loss: 0.8853 - val_acc: 0.7208\n",
      "Epoch 8/20\n",
      "915/915 [==============================] - 220s 240ms/step - loss: 0.4026 - acc: 0.8770 - val_loss: 0.8640 - val_acc: 0.7165\n",
      "Epoch 9/20\n",
      "915/915 [==============================] - 214s 234ms/step - loss: 0.3184 - acc: 0.9059 - val_loss: 1.0044 - val_acc: 0.7068\n",
      "Epoch 10/20\n",
      "915/915 [==============================] - 215s 235ms/step - loss: 0.3368 - acc: 0.8955 - val_loss: 0.8925 - val_acc: 0.7299\n",
      "Epoch 11/20\n",
      "915/915 [==============================] - 207s 226ms/step - loss: 0.2816 - acc: 0.9165 - val_loss: 0.8290 - val_acc: 0.7550\n",
      "Epoch 12/20\n",
      "915/915 [==============================] - 204s 222ms/step - loss: 0.2528 - acc: 0.9252 - val_loss: 0.9816 - val_acc: 0.7331\n",
      "Epoch 13/20\n",
      "915/915 [==============================] - 13104s 14s/step - loss: 0.2654 - acc: 0.9196 - val_loss: 0.7521 - val_acc: 0.7810\n",
      "Epoch 14/20\n",
      "915/915 [==============================] - 210s 229ms/step - loss: 0.2984 - acc: 0.9053 - val_loss: 0.8330 - val_acc: 0.7099\n",
      "Epoch 15/20\n",
      "915/915 [==============================] - 209s 229ms/step - loss: 0.2356 - acc: 0.9319 - val_loss: 0.9520 - val_acc: 0.7427\n",
      "Epoch 16/20\n",
      "915/915 [==============================] - 215s 235ms/step - loss: 0.2078 - acc: 0.9405 - val_loss: 1.0231 - val_acc: 0.7334\n",
      "Epoch 17/20\n",
      "915/915 [==============================] - 208s 227ms/step - loss: 0.2105 - acc: 0.9378 - val_loss: 0.8301 - val_acc: 0.7807\n",
      "Epoch 18/20\n",
      "915/915 [==============================] - 207s 226ms/step - loss: 0.2036 - acc: 0.9397 - val_loss: 0.9821 - val_acc: 0.7504\n",
      "Epoch 19/20\n",
      "915/915 [==============================] - 210s 230ms/step - loss: 0.2141 - acc: 0.9379 - val_loss: 0.9323 - val_acc: 0.7657\n",
      "Epoch 20/20\n",
      "915/915 [==============================] - 206s 225ms/step - loss: 0.2237 - acc: 0.9342 - val_loss: 0.9096 - val_acc: 0.7592\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_One_Multiple_Output()\n",
    "eS = EarlyStopping(monitor='acc', min_delta=0.00001, patience=5)\n",
    "mCp = ModelCheckpoint('Model_1_2_3_Multiple_Output.h5', monitor='val_loss', save_best_only=True)\n",
    "history = model.fit(X[:,:,1:], Y, epochs=20, batch_size=1, validation_data=(X_Test[:,:,1:],Y_Test),shuffle = True,callbacks = [eS,mCp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(votes):\n",
    "    # Input vector of predicted classes in ones strike\n",
    "    # Output the most frequent class in the strike \n",
    "    nbr_of_classes = 4\n",
    "    nbr_of_votes = len(votes)\n",
    "    votes_each_class = np.zeros((nbr_of_classes,))\n",
    "    \n",
    "    for i in range(nbr_of_votes):\n",
    "        votes_each_class[votes[i]] = 1 + votes_each_class[votes[i]]\n",
    "    \n",
    "    majority_vote = np.argmax(votes_each_class,axis = 0)\n",
    "    \n",
    "    return majority_vote "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote_strikes(pred_y,test_y):\n",
    "    # Take predictions as input\n",
    "    # Outputs the majority vote after, taking the class with maximal prob for each time step \n",
    "    nbr_of_samples = pred_y.shape[0]\n",
    "    time_step = pred_y.shape[1]\n",
    "    pred_y_new = np.zeros((nbr_of_samples,time_step))\n",
    "    true_y = np.zeros((nbr_of_samples,time_step))\n",
    "    \n",
    "    for i in range(nbr_of_samples):\n",
    "        strike = pred_y[i,:,:]\n",
    "        votes = np.argmax(strike, axis=1)\n",
    "        majority_v = majority_vote(votes)\n",
    "        pred_y_new[i,:] = majority_v\n",
    "        \n",
    "        true_class = np.argmax(test_y[i,:,:], axis=1)\n",
    "        true_y[i,:] = true_class\n",
    "        \n",
    "    return pred_y_new, true_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote_strikes_max_prob(pred_y,test_y):\n",
    "    # Take predictions as input\n",
    "    # Outputs the majority vote, as the class with maximal total prob over all time steps \n",
    "    nbr_of_samples = pred_y.shape[0]\n",
    "    time_step = pred_y.shape[1]\n",
    "    pred_y_new = np.zeros((nbr_of_samples,time_step))\n",
    "    true_y = np.zeros((nbr_of_samples,time_step))\n",
    "    \n",
    "    for i in range(nbr_of_samples):\n",
    "        strike = pred_y[i,:,:]\n",
    "        strike_sum = np.sum(strike,axis = 0)\n",
    "        majority_v = np.argmax(strike_sum,axis = 0)\n",
    "        \n",
    "        pred_y_new[i,:] = majority_v\n",
    "        \n",
    "        true_class = np.argmax(test_y[i,:,:], axis=1)\n",
    "        true_y[i,:] = true_class\n",
    "    \n",
    "    return pred_y_new, true_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(763, 140)\n",
      "(763, 140)\n",
      "Accuracy: 0.81\n",
      "(763, 140)\n",
      "(763, 140)\n",
      "Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('LSTM_1_2_3_Majority_Vote_After.h5')\n",
    "predY = model.predict(X_Test[:,:,1:])\n",
    "pred_y, true_y = majority_vote_strikes_max_prob(predY,Y_Test)\n",
    "\n",
    "print(pred_y.shape)\n",
    "print(true_y.shape)\n",
    "acc = accuracy_score(true_y[:,0], pred_y[:,0])\n",
    "print(\"Accuracy: %.2f\" % acc)\n",
    "\n",
    "pred_y_1, true_y = majority_vote_strikes(predY,Y_Test)\n",
    "\n",
    "print(pred_y_1.shape)\n",
    "print(true_y.shape)\n",
    "acc = accuracy_score(true_y[:,0], pred_y_1[:,0])\n",
    "print(\"Accuracy: %.2f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
