{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import Series\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Activation, BatchNormalization\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the Gear2 data\n",
    "Gear2Files = ['./Gear2/segment2.csv', './Gear2/segment3.csv','./Gear2/segment4.csv',\n",
    "              './Gear2/segment5.csv','./Gear2/segment6.csv']\n",
    "\n",
    "X_Gear2=[0] * len(Gear2Files)\n",
    "Y_Gear2=[0] * len(Gear2Files)\n",
    "for index,file in enumerate(Gear2Files):\n",
    "    X_Gear2[index] = pd.read_csv(file);\n",
    "    Y_Gear2[index] = pd.DataFrame(data= np.full((X_Gear2[index].shape[0],1), 2));\n",
    "    X_Gear2[index] = X_Gear2[index].assign(Gear=Y_Gear2[index].values);\n",
    "\n",
    "# Read the Gear3 data\n",
    "Gear3Files = ['./Gear3/segment1.csv', './Gear3/segment2.csv','./Gear3/segment3.csv',\n",
    "              './Gear3/segment4.csv','./Gear3/segment5.csv', './Gear3/segment6.csv']\n",
    "\n",
    "X_Gear3=[0] * len(Gear3Files)\n",
    "Y_Gear3=[0] * len(Gear3Files)\n",
    "for index,file in enumerate(Gear3Files):\n",
    "    X_Gear3[index] = pd.read_csv(file);\n",
    "    Y_Gear3[index] = pd.DataFrame(data= np.full((X_Gear3[index].shape[0],1), 3));\n",
    "    X_Gear3[index] = X_Gear3[index].assign(Gear=Y_Gear3[index].values);\n",
    "\n",
    "# Read the Gear4 data\n",
    "Gear4Files = ['./Gear4/segment2.csv','./Gear4/segment3.csv','./Gear4/segment4.csv',\n",
    "              './Gear4/segment5.csv', './Gear4/segment6a.csv','./Gear4/segment6b.csv']\n",
    "\n",
    "X_Gear4=[0] * len(Gear4Files)\n",
    "Y_Gear4=[0] * len(Gear4Files)\n",
    "for index,file in enumerate(Gear4Files):\n",
    "    X_Gear4[index] = pd.read_csv(file);\n",
    "    Y_Gear4[index] = pd.DataFrame(data= np.full((X_Gear4[index].shape[0],1), 4));\n",
    "    X_Gear4[index] = X_Gear4[index].assign(Gear=Y_Gear4[index].values);\n",
    "\n",
    "# Read the Gear 5 data\n",
    "Gear5Files = ['./Double/segment1.csv','./Double/segment2.csv','./Double/segment3.csv',\n",
    "              './Double/segment4.csv', './Double/segment5.csv','./Double/segment7.csv']\n",
    "\n",
    "X_Gear5=[0] * len(Gear5Files)\n",
    "Y_Gear5=[0] * len(Gear5Files)\n",
    "for index,file in enumerate(Gear5Files):\n",
    "    X_Gear5[index] = pd.read_csv(file);\n",
    "    Y_Gear5[index] = pd.DataFrame(data= np.full((X_Gear5[index].shape[0],1), 5));\n",
    "    X_Gear5[index] = X_Gear5[index].assign(Gear=Y_Gear5[index].values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement moving average for a window size of 3, and split the segments such that each has 750 time-steps\n",
    "\n",
    "limit = 750\n",
    "features = list(X_Gear2[0].columns);\n",
    "scaledFeatures = [item for item in features if item not in ['t','Gear']]\n",
    "\n",
    "XGear=[]\n",
    "for index in range(len(X_Gear2)):\n",
    "    dataG2 = X_Gear2[index];\n",
    "    x = dataG2[scaledFeatures];\n",
    "    rolling = x.rolling(window=3);\n",
    "    rolling_mean = rolling.mean();\n",
    "    X_Gear2[index][scaledFeatures] = rolling_mean;\n",
    "    dataG2 = X_Gear2[index].iloc[3:, :];\n",
    "    gearRange = math.ceil(len(dataG2)/limit);\n",
    "    XGear += [dataG2[t*limit:t*limit + limit] for t in range(gearRange)];  \n",
    "    \n",
    "for index in range(len(X_Gear3)):\n",
    "    dataG3 = X_Gear3[index];\n",
    "    x = dataG3[scaledFeatures];\n",
    "    rolling = x.rolling(window=3);\n",
    "    rolling_mean = rolling.mean();\n",
    "    X_Gear3[index][scaledFeatures] = rolling_mean;\n",
    "    dataG3 = X_Gear3[index].iloc[3:, :];\n",
    "    gearRange = math.ceil(len(dataG3)/limit);\n",
    "    XGear += [dataG3[t*limit:t*limit + limit] for t in range(gearRange)];  \n",
    "    \n",
    "for index in range(len(X_Gear4)):\n",
    "    dataG4 = X_Gear4[index];\n",
    "    x = dataG4[scaledFeatures];\n",
    "    rolling = x.rolling(window=3);\n",
    "    rolling_mean = rolling.mean();\n",
    "    X_Gear4[index][scaledFeatures] = rolling_mean;\n",
    "    dataG4 = X_Gear4[index].iloc[3:, :];\n",
    "    gearRange = math.ceil(len(dataG4)/limit);\n",
    "    XGear += [dataG4[t*limit:t*limit + limit] for t in range(gearRange)];  \n",
    "    \n",
    "    \n",
    "for index in range(len(X_Gear5)):\n",
    "    dataG5 = X_Gear5[index];\n",
    "    x = dataG5[scaledFeatures];\n",
    "    rolling = x.rolling(window=3);\n",
    "    rolling_mean = rolling.mean();\n",
    "    X_Gear5[index][scaledFeatures] = rolling_mean;\n",
    "    dataG5 = X_Gear5[index].iloc[3:, :];\n",
    "    gearRange = math.ceil(len(dataG5)/limit);\n",
    "    XGear += [dataG5[t*limit:t*limit + limit] for t in range(gearRange)];  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample data after rolling\n",
    "\n",
    "# features = list(X_Gear2[0].columns);\n",
    "# scaledFeatures = [item for item in features if item not in ['t','Gear']]\n",
    "\n",
    "# X2_Gear2_New = pd.DataFrame(X_Gear2[0][scaledFeatures])\n",
    "\n",
    "# rolling = X2_Gear2_New.rolling(window=3)\n",
    "# rolling_mean = rolling.mean()\n",
    "\n",
    "# X2_Gear2_New['fL'].plot()\n",
    "# rolling_mean['fL'].plot(color='yellow')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = XGear[:] # Copy words\n",
    "shuffle(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.concat(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(X);\n",
    "\n",
    "data.reset_index(inplace = True, drop = True)\n",
    "for i in range(len(data)):\n",
    "    data.loc[i,'t'] = i*0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation\n",
    "# Feature normalization\n",
    "# Normalize Time Series Data\n",
    "# Source : https://machinelearningmastery.com/normalize-standardize-time-series-data-python/\n",
    "\n",
    "# Normalization is a rescaling of the data from the original range so that all values are within the range of 0 and 1.\n",
    "# useful when your time series data has input values with differing scales.\n",
    "features = list(data.columns);\n",
    "scaledFeatures = [item for item in features if item not in ['t','Gear']]\n",
    "\n",
    "for i in range(len(scaledFeatures)):\n",
    "    feature = scaledFeatures[i];\n",
    "    print('Scaling feature : ', scaledFeatures[i])\n",
    "    values = X[feature].values.reshape(-1,1);\n",
    "    values = values.astype('float32');\n",
    "    scaler = MinMaxScaler(feature_range = (0,1));\n",
    "    scaled_f = scaler.fit_transform(values);\n",
    "    X[feature] = scaled_f;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create one-hot Y vectors\n",
    "features.remove('Gear')\n",
    "features.remove('x')\n",
    "features.remove('y')\n",
    "features.remove('v')\n",
    "X = data[features]\n",
    "Y = data['Gear']\n",
    "# Create one-hot Y vectors\n",
    "Y_onehot = pd.get_dummies(Y).values;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timesteps = 1\n",
    "XNew = X.reshape(X.shape[0],timesteps,18)\n",
    "YNew = Y.reshape(Y.shape[0],timesteps,4)\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(XNew, YNew, test_size=0.2);\n",
    "\n",
    "trainX, valX, trainY, valY = train_test_split(trainX, trainY, test_size=0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# design and fit our LSTM network\n",
    "l1 = 0;\n",
    "l2 = 0;\n",
    "hidden_dim = 128;\n",
    "epochs = 250;\n",
    "batch_size = 100;\n",
    "\n",
    "model = Sequential();\n",
    "model.add(LSTM(hidden_dim, \n",
    "               kernel_regularizer = regularizers.l1_l2(l1=l1, l2=l2), \n",
    "               return_sequences = True, \n",
    "               input_shape = (timesteps, 17)));\n",
    "model.add(Dense(4, activation = 'relu'));\n",
    "model.add(Dense(4, activation = 'softmax'));\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "history = model.fit(trainX[:,:,1:], trainY, epochs=epochs, batch_size=batch_size, validation_data=(valX[:,:,1:],valY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.figure(0,figsize=(10, 8))\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.figure(0,figsize=(10, 8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "predictions = model.predict_classes(testX[:,:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(testX[:,:,1:], testY, verbose=2)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timeTest = np.array(testX[:,:,0])\n",
    "forceLeftTest = np.array(testX[:,:,1])\n",
    "forceRightTest = np.array(testX[:,:,9])\n",
    "predTest = np.array(predictions+2)\n",
    "realTest = np.array(np.argmax(testY, axis=2)+2)\n",
    "result = np.concatenate((timeTest,forceLeftTest, forceRightTest, predTest, realTest), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind=np.argsort(result[:,0])\n",
    "result2 = result[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0,figsize=(20, 5))\n",
    "color = {2:'red',3:'orange',4:'pink', 5:'blue'}\n",
    "plt.title('Force Left(Predictions)')\n",
    "for i in range(2,6):\n",
    "    classResult = result[result[:,3]==i]\n",
    "    plt.scatter(classResult[:,0],classResult[:,1],c =color[i],label='Gear ' + str(i))\n",
    "    plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(0,figsize=(20, 5))\n",
    "color = {2:'red',3:'orange',4:'pink', 5:'blue'}\n",
    "plt.title('Force Left(True Class)')\n",
    "for i in range(2,6):\n",
    "    classRealResult = result[result[:,4]==i]\n",
    "    plt.scatter(classRealResult[:,0],classRealResult[:,1],c =color[i],label='Gear ' + str(i))\n",
    "    plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(0,figsize=(20, 5))\n",
    "plt.title('Force Right(Predictions)')\n",
    "for i in range(2,6):\n",
    "    classResult = result[result[:,3]==i]\n",
    "    plt.scatter(classResult[:,0],classResult[:,2],c =color[i],label='Gear ' + str(i))\n",
    "    plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(0,figsize=(20, 5))\n",
    "color = {2:'red',3:'orange',4:'pink', 5:'blue'}\n",
    "plt.title('Force Right(True Class)')\n",
    "for i in range(2,6):\n",
    "    classRealResult = result[result[:,4]==i]\n",
    "    plt.scatter(classRealResult[:,0],classRealResult[:,2],c =color[i],label='Gear ' + str(i))\n",
    "    plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,6):\n",
    "    classPredResult = result[result[:,3]==i]\n",
    "    classRealResult = result[result[:,4]==i]\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(20,8))\n",
    "    \n",
    "    ax1.set_title('Force Left for Gear '+str(i) +': Real vs Prediction') \n",
    "    ax1.scatter(classRealResult[:,0],classRealResult[:,1],c ='red',label='Real Gear ' + str(i))\n",
    "    ax1.scatter(classPredResult[:,0],classPredResult[:,1],c ='blue',label='Predicted Gear ' + str(i))\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    \n",
    "    ax2.set_title('Force Right for Gear '+str(i) +': Real vs Prediction') \n",
    "    ax2.scatter(classRealResult[:,0],classRealResult[:,2],c ='red',label='Real Gear ' + str(i))\n",
    "    ax2.scatter(classPredResult[:,0],classPredResult[:,2],c ='blue',label='Predicted Gear ' + str(i))\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of data for each gear in training set\n",
    "i = (np.argmax(trainY, axis = 2)) + 2\n",
    "\n",
    "# Count of data for each gear in test set\n",
    "j = (np.argmax(testY, axis = 2)) + 2\n",
    "\n",
    "plt.hist(i, label = '# Train set')\n",
    "plt.hist(j, label = '# Test set')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
